# app.py
# A self-contained web application for document analysis using Streamlit.
# This single file handles UI, server logic, and file operations.

import streamlit as st
import os
import time

# --- 1. Core Logic & Setup (Backend part) ---

# Directory to store uploaded files.
UPLOAD_DIRECTORY = "./uploaded_documents"
if not os.path.exists(UPLOAD_DIRECTORY):
    os.makedirs(UPLOAD_DIRECTORY)

def save_uploaded_file(uploaded_file):
    """Saves the uploaded file to the server's directory."""
    try:
        if uploaded_file is not None:
            file_path = os.path.join(UPLOAD_DIRECTORY, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            return True
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    return False

def get_file_list():
    """Retrieves the list of saved files, sorted alphabetically."""
    return sorted(os.listdir(UPLOAD_DIRECTORY))

def delete_file(filename):
    """Deletes the specified file from the directory."""
    try:
        file_path = os.path.join(UPLOAD_DIRECTORY, filename)
        if os.path.exists(file_path):
            os.remove(file_path)
            return True
    except Exception as e:
        st.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return False

def get_answer_from_ai(question, context_files):
    """
    (Core AI Function) Generates an answer based on the question and context files.
    In a real application, this function would integrate with libraries like
    LangChain, LlamaIndex, or directly call an AI model API (e.g., GPT).
    """
    if not question.strip():
        return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    if not context_files:
        return "ë‹µë³€ì˜ ê·¼ê±°ê°€ ë  ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

    # --- Placeholder for actual AI logic ---
    # 1. Read content from files in `context_files`.
    # 2. Create a prompt for the AI model, including the context and question.
    # 3. Call the AI model's API.
    # 4. Return the generated answer.
    # For this example, we'll simulate a delay and return a mock response.
    with st.spinner("AIê°€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        time.sleep(2) # Simulate AI thinking time
        mock_answer = (
            f"ì§ˆë¬¸: '{question}'\n\n"
            f"ë‹µë³€: ì´ ë‹µë³€ì€ '{', '.join(context_files)}' íŒŒì¼(ë“¤)ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ì˜ˆì‹œì…ë‹ˆë‹¤. "
            "ì‹¤ì œ ì‹œìŠ¤í…œì—ì„œëŠ” ì´ ë¶€ë¶„ì— AI ëª¨ë¸ì´ ì—°ë™ë˜ì–´ ì‹¬ì¸µì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        )
    return mock_answer
    # --- End of placeholder ---


# --- 2. UI Rendering (Frontend part using Streamlit) ---

# Set page configuration (title, icon, layout)
st.set_page_config(
    page_title="í†µí•© ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="centered"
)

# Main title of the application
st.title("ğŸ¤– í†µí•© ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.caption("Pythonê³¼ Streamlitë§Œìœ¼ë¡œ êµ¬í˜„ëœ UI ë° ì„œë²„ í†µí•© ì• í”Œë¦¬ì¼€ì´ì…˜")

# --- Section 1: File Upload ---
with st.container(border=True):
    st.header("1. ë¬¸ì„œ ì—…ë¡œë“œ")
    # File uploader widget
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  ë¬¸ì„œë¥¼ ì—¬ê¸°ì— ì—…ë¡œë“œí•˜ì„¸ìš”.",
        type=['pdf', 'txt', 'md', 'docx'],
        label_visibility="collapsed"
    )

    if uploaded_file:
        if save_uploaded_file(uploaded_file):
            st.success(f"âœ… **{uploaded_file.name}** íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            # Rerun the script to immediately reflect the change in the file list
            st.rerun()

# --- Section 2: File Management ---
with st.container(border=True):
    st.header("2. ì—…ë¡œë“œëœ ë¬¸ì„œ ê´€ë¦¬")
    file_list = get_file_list()

    if not file_list:
        st.info("í˜„ì¬ ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else:
        # Display each file with a delete button
        for filename in file_list:
            col1, col2 = st.columns([0.8, 0.2])
            with col1:
                st.markdown(f"ğŸ“„ **{filename}**")
            with col2:
                # Use a unique key for each button to ensure they work independently
                if st.button("ì‚­ì œ", key=f"delete_{filename}"):
                    if delete_file(filename):
                        st.toast(f"ğŸ—‘ï¸ '{filename}' íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()

# --- Section 3: Question & Answer ---
with st.container(border=True):
    st.header("3. AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
    # Text input for the user's question
    question = st.text_input(
        "ì—…ë¡œë“œëœ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ë¬¸ì„œì˜ í•µì‹¬ ì£¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    )

    # Submit button
    if st.button("ë‹µë³€ ìƒì„±", type="primary", use_container_width=True):
        answer = get_answer_from_ai(question, get_file_list())
        st.info(answer)