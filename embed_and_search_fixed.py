
import os
import json
import re
from pathlib import Path
import pdfplumber
from langchain_community.vectorstores import Chroma, FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings
from langchain.docstore.document import Document

# 1. ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text(file_path):
    ext = Path(file_path).suffix.lower()
    if ext == ".pdf":
        with pdfplumber.open(file_path) as pdf_obj:
            return "\n".join([page.extract_text() or "" for page in pdf_obj.pages])
    return Path(file_path).read_text(encoding="utf-8")

# 2. êµ¬ì¡°í™”: ì‚¬ë¡€/ê·œì¹™ ë¸”ë¡ ì¶”ì¶œ
def parse_cases(text):
    pattern = re.split(r"(?:â—‰|<ì‚¬ë¡€\s*\d+>|#\s*ì‚¬ë¡€\s*\d+|ì‚¬ë¡€\s*\d+|ì˜ˆì‹œ\s*\d+|â– )", text)
    blocks = []
    for block in pattern:
        lines = block.strip().splitlines()
        if len(lines) < 2:
            continue
        title = lines[0].strip()
        body = "\n".join(lines[1:]).strip()
        summary = " / ".join([l for l in body.splitlines() if l.strip()][:5])
        category = "ì‚¬ë¡€" if "ì‚¬ë¡€" in title else "ê·œì¹™" if "ë²•ì¹™" in title else "ê¸°íƒ€"
        blocks.append({"ì œëª©": title, "ë‚´ìš©": body, "ìš”ì•½": summary, "êµ¬ë¶„": category})
    return blocks

# 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥
def embed_and_save(blocks, db_dir, db_type="Chroma", embed_type="HF"):
    docs = [Document(page_content=f"[{b['êµ¬ë¶„']}] {b['ì œëª©']}\n{b['ë‚´ìš©']}", metadata={"title": b["ì œëª©"]}) for b in blocks]
    emb = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2") if embed_type == "HF" else OpenAIEmbeddings()

    if db_type == "Chroma":
        db = Chroma.from_documents(docs, emb, persist_directory=db_dir)
        db.persist()
    elif db_type == "FAISS":
        db = FAISS.from_documents(docs, emb)
        FAISS.save_local(db, db_dir)
    return db_dir

# 4. ì‹¤í–‰
if __name__ == "__main__":
    files = [
        "C:/Users/oo/Desktop/new4/Book5_new.md",
        "C:/Users/oo/Desktop/new4/Part4 ìˆ˜ì•”ëª…ë¦¬ì˜ ë¶„ì„ë°©ë²•.md"
    ]

    all_blocks = []
    print("ğŸ“‚ ë¬¸ì„œ ë¡œë”© ì¤‘...")
    for file_path in files:
        raw_text = extract_text(file_path)
        parsed_blocks = parse_cases(raw_text)
        all_blocks.extend(parsed_blocks)

    print(f"ğŸ” ì´ {len(all_blocks)}ê°œ ë¸”ë¡ êµ¬ì¡°í™” ì™„ë£Œ")
    with open("saju_structured_all.json", "w", encoding="utf-8") as f:
        json.dump(all_blocks, f, ensure_ascii=False, indent=2)

    print("ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ: saju_structured_all.json")

    # ë²¡í„° DB ì €ì¥
    db_output = embed_and_save(all_blocks, db_dir="saju_vector_db", db_type="Chroma", embed_type="HF")
    print(f"âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {db_output}")
